Namespace(dataset_name=None, dataset_config_name=None, train_file='/storage/ukp/work/matzken/fplm/ft_gpt2/experiments/data/original-train.txt', validation_file='/storage/ukp/work/matzken/fplm/ft_gpt2/experiments/data/original-test.txt', validation_split_percentage=5, model_name_or_path='gpt2-medium', config_name=None, tokenizer_name='gpt2-medium', use_slow_tokenizer=False, do_ref_model=True, add_dp=True, per_device_train_batch_size=2, per_device_eval_batch_size=1, learning_rate=1e-05, weight_decay=0.01, num_train_epochs=5, max_train_steps=None, gradient_accumulation_steps=128, eval_steps=1000, lr_scheduler_type=<SchedulerType.CONSTANT: 'constant'>, num_warmup_steps=0, output_dir='/storage/ukp/work/matzken/fplm/ft_gpt2/experiments/sanity_check_2', seed=1234, model_type=None, block_size=512, preprocessing_num_workers=None, overwrite_cache=True, no_keep_linebreaks=False, push_to_hub=False, hub_model_id=None, hub_token=None, train_head_only=False, train_layer_n_only=None, lora_dim=4, lora_dropout=0.0, lora_alpha=32, noise_multiplier=1.2, objective='dp', per_sample_max_grad_norm=0.0, target_epsilon=None, dropout_debias=False)
model_params (million) 0.393216
model_params (million) 0.393216
cuda:0
model_params (million) 0.393216
training epoch 0
*************end of epoch 0 eval 
threshold_ref is:  0.9998470544815063
threshold is:  4.17918586730957
saving model here at step 489 and epoch 0 with ppl 91.3384779044565
correct cnt  ref is:  4910 all is:  124923 ratio is:  0.03930421139421884
correct cnt is:  10914 all is:  124923 ratio is:  0.08736581734348359
epoch 0: perplexity: 91.3384779044565 perplexity_train: 89.7223869761756
____
0.03930421139421884
0.08736581734348359
91.3384779044565
89.7223869761756
0.03835932246806058
0.08632448528705453
0.2804963708733318
0.46732535968105393
_____
End of epoch 0, we have epsilon 0.5147572480717517 for alpha 17.0 from privacy engine
training epoch 1
*************end of epoch 1 eval 
threshold_ref is:  0.9997161626815796
threshold is:  4.178798675537109
saving model here at step 978 and epoch 1 with ppl 91.29284515523673
correct cnt  ref is:  5794 all is:  124923 ratio is:  0.046380570431385736
correct cnt is:  10928 all is:  124923 ratio is:  0.08747788637800885
epoch 1: perplexity: 91.29284515523673 perplexity_train: 89.67922934445038
____
0.046380570431385736
0.08747788637800885
91.29284515523673
89.67922934445038
0.04812526015817617
0.08648458262623675
0.3284527972027972
0.4677866297194319
_____
End of epoch 1, we have epsilon 0.5337491503085463 for alpha 17.0 from privacy engine
training epoch 2
step 1000 epoch 2 perplexity: 91.29358519919063
*************end of epoch 2 eval 
threshold_ref is:  0.9996048212051392
threshold is:  4.178356170654297
saving model here at step 1467 and epoch 2 with ppl 91.25580709101204
correct cnt  ref is:  6180 all is:  124923 ratio is:  0.04947047381186811
correct cnt is:  10916 all is:  124923 ratio is:  0.08738182720555862
epoch 2: perplexity: 91.25580709101204 perplexity_train: 89.64387182083219
____
0.04947047381186811
0.08738182720555862
91.25580709101204
89.64387182083219
0.05014248663187218
0.08635650475489097
0.3375727527484372
0.4674176776429809
_____
End of epoch 2, we have epsilon 0.5527410525453409 for alpha 17.0 from privacy engine
training epoch 3
*************end of epoch 3 eval 
threshold_ref is:  0.9995227456092834
threshold is:  4.178210735321045
saving model here at step 1956 and epoch 3 with ppl 91.22722276578541
correct cnt  ref is:  6012 all is:  124923 ratio is:  0.0481256453975649
correct cnt is:  10926 all is:  124923 ratio is:  0.08746187651593382
epoch 3: perplexity: 91.22722276578541 perplexity_train: 89.6167752514423
____
0.0481256453975649
0.08746187651593382
91.22722276578541
89.6167752514423
0.04908584419326951
0.08648458262623675
0.33282674772036475
0.4677866297194319
_____
End of epoch 3, we have epsilon 0.5717329547821355 for alpha 17.0 from privacy engine
training epoch 4
saving model here at step 2000 and epoch 4 with ppl 91.22587425933293
step 2000 epoch 4 perplexity: 91.22587425933293
*************end of epoch 4 eval 
threshold_ref is:  0.9994322061538696
threshold is:  4.17788028717041
saving model here at step 2440 and epoch 4 with ppl 91.1946901717172
correct cnt  ref is:  6116 all is:  124923 ratio is:  0.04895815822546689
correct cnt is:  10924 all is:  124923 ratio is:  0.08744586665385878
epoch 4: perplexity: 91.1946901717172 perplexity_train: 89.58520141716903
____
0.04895815822546689
0.08744586665385878
91.1946901717172
89.58520141716903
0.049726233549998396
0.0864525631584003
0.33571119757890183
0.46769443963277324
_____
End of epoch 4, we have epsilon 0.5905306657895149 for alpha 17.0 from privacy engine
*************end of training 
threshold_ref is:  0.9994322061538696
threshold is:  4.17788028717041
end of training epsilon privacy engine 0.5905306657895149
correct cnt  ref is:  6116 all is:  124923 ratio is:  0.04895815822546689
correct cnt is:  10924 all is:  124923 ratio is:  0.08744586665385878
end of training perplexity: 91.1946901717172 perplexity_train: 89.58520141716903
____
0.04895815822546689
0.08744586665385878
91.1946901717172
89.58520141716903
0.049726233549998396
0.0864525631584003
0.33571119757890183
0.46769443963277324
_____
